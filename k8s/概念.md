> kubernetes 协调一个高可用计算机集群，每一个计算机作为独立单元互相连接工作。

k8s 集群包含两种类型的资源

- **Master** 调度整个集群
  协调集群中所有的活动，例如调用应用、维护应用的所有状态、应用扩容以及推出新的更新

- **Nodes** 负责运行应用
  **Node** 工作节点，可以是一个虚拟机或物理机，充当工作机器的角色，每一个 **Node** 都有一个 **Kubelet**，管理 **Node** 与 **Master** 通信的代理。 **Node** 还具有处理容器操作的工具，例如 **Docker** 或 **rkt**

> Node 使用 Master 暴露的 K8S API 与 Master 通信。

### K8S 组件

##### 控制平面组件(Control Plane Components)

用于对集群的全局决策(调度)、以及检测和响应集群事件。
控制平面组件可以在集群中任何节点运行。然而为了简单起见，设置脚本通常会在同一个计算机启动所有控制平面组件，并且不会在计算机运行用户容器。

- kube-apiserver
  该组件公开了 K8S API。 是 K8S 控制面的前端

- etcd
  该组件是一个兼具一致性和高可用的键值数据库，可以作为保存 K8S 所有集群数据的后台服务器。

* kube-scheduler
  该组件负责监视新创建的、未指定运行结点（Node）的 **Pods**，选择节点让 **Pod** 在上面运行。

* kube-controller-manager
  该组件是运行控制器进程的组件，所有控制器都被编译到同一个可执行文件，并在一个进程中运行
  - 节点控制器（Node Controller）：负责在节点出现故障时进行通知和响应
  - 任务控制器（Job Controller）：检测代表一次性任务的 Job 对象，然后创建 **Pods** 运行这些任务直到完成
  - 端点控制器（Endpoints Controller）：填充端点（Endpoints）对象（即加入 Service 和 Pod）
  - 服务账户和令牌服务器（Service Account && Token Controllers）：为新的命名空间创建默认账户和 API 访问令牌。

##### Node 组件

**Node** 组件在每一个节点运行，维护运行的 **Pods** 并提供 K8S 运行环境

- kubelet

### K8S 对象

在 K8S 系统中， K8S 对象是一个表示集群状态的持久化对象，它们描述了

- 哪些容器化应用在运行（以及在哪个节点）
- 可以被应用使用的资源
- 关于应用运行时表现的策略，比如重启、升级、以及容错策略

> 几乎每一个 K8S 对象包含两个嵌套对象字段，负责管理对象的配置： `对象spec（规约）`、`对象status（状态）`

> 对于具有 `spec` 的对象，创建时必须设置其内容，描述希望对象所具有的特性：_期望状态（Desired State）_

> `status` 描述了对象的 _当前状态（Current State）_

### Kubernetes Deployment

**Kubernetes Deployment** 指挥 Kubernetes 如何创建和更新应用程序的实例。创建 **Kubernetes Deployment** 后， **Kubernetes master** 将应用程序实例调度到集群中的各个节点上。

创建实例后， **Kubernetes Deployment** 控制器会持续监视这些实例，如果托管实例的节点关闭或被删除， **Deployment** 控制器会将该实例替换为集群中另一个节点的实例。提供了一种自我修复机制来解决机器故障维护问题

### kubectl

在 K8S 运行的 Pods 是在独立网络中运行的，默认情况下，在同一集群中的其它 Pods 和服务中是可见的，但在该网络外是不可见的。当使用 **Kubectl** 时，通过 API 端点和 应用程序交互

**kubectl** 命令可以创建一个代理，将通信转发到集群范围内的专用网络

### Node(工作节点)

**Node（工作节点）** 是 K8S 中负责计算的机器，可能是 VM 或 物理计算机，具体取决于集群。多个 **Pod** 可以在一个工作节点上运行。

每个工作节点由主节点管理，工作节点可以由多个 **Pod**，K8S 主节点会自动处理在集群中的工作节点上调度 **Pod**。主节点的自动调度考量了每个工作节点的可用资源。

### Pod

**pod** 是 K8S 中管理、创建、计划的最小单元。
一个 **pod** 相当于一个共享 **context** 的配置组，在同一 **context** 下，应用可能还有独立的 **cgroups** 隔离机制，一个 **Pod** 是容器环境下的 _“逻辑主机”_，可能是包含一个或多个紧密相连的应用，这些应用可能在同一物理主机或虚拟机中。

**Pod** 的 context 可以理解成多个 linux 命名空间的联合

- PID 命名空间（同一个 Pod 中应用可以看到其它进程）
- 网络 命名空间（同一个 Pod 的中的应用对相同的 IP 地址和端口有权限）
- IPC 命名空间（同一个 Pod 中的应用可以通过 VPC 或者 POSIX 进行通信）
- UTS 命名空间（同一个 Pod 中的应用共享一个主机名称）

##### 资源的共享及通信

同一个 **Pod** 中的应用可以共享磁盘，磁盘是 **Pod** 级别的，应用可以通过文件系统调用

**Pod** 中的应用均使用相同的网络命名空间及端口，并且可以通过 _localhost_ 发现并沟通其它应用，每一个 _Pod_ 都有扁平化的网络命名空间下 IP 地址，它是 **Pod** 可以和其它物理机及其它的容器进行无障碍通信，主机名称可以设置为 **Pod** 名称

**Pod** 还定义了一系列的共享磁盘，磁盘让这些数据在容器重启的时候不会丢失并且可以将这些数据在 **Pod** 的应用进行共享。

> 当一个 **Node** 挂掉之后，在 Node 上运行的 **Pod** 也会消亡

> K8S 集群中每一个 **Pod** 都有一个唯一的 IP 地址，

##### 管理

**Pod** 通过提供一个高层次抽象而不是底层的接口简化了应用的部署及管理， **Pod** 作为最小的部署及管理单位，位置管理，拷贝管理，资源共享、依赖关系都是自动处理的

##### Pod 的使用

**Pod** 可以作为垂直应用整合的载体，但它主要特点是支持同地协作、同地管理程序。例如：

- 内容管理系统，文件和数据加载，本地缓存等等
- 日志和检查点备份，压缩，循环，快照等等
- 数据交换监控，日志追踪，日志记录和监控适配器，以及事件发布等等
- 代理，网桥，适配器
- 控制，管理，配置，更新

##### Pod 的持久性

**Pod** 并不是被设计成一个持久化的资源，它不会在调度失败，节点崩溃，或者其它回收中（例如因为资源缺乏，或者其它的维护中）幸存下来。

总体来说，应该直接创建 **Pod**，并一直使用 **controller(replication controller)** ,即使是一个节点的情况，这是因为 **controller** 提供了集群范围内的自我修复，以及复制还有展示管理。

##### 为什么使用 **Pod**

1. 透明 **Pod**中的容器对基础设施可见使得基础设施可以给容器提供服务，例如线程管理和资源监控，
2. 解耦软件依赖关系，独立的容器可以独立的进行重建和重新发布，K8S 甚至会在将来支持独立容器的实时更新
3. 易用，用户不需要运行自己的线程管理器，也不需要关系程序的信号以及异常结束码等
4. 高效，因为基础设施承载了更多的责任，所以容器可以更加高效

### Service

**Service(服务)** 是一种抽象概念，它定义了 **Pod** 的*逻辑集*和*访问 Pod* 协议，使得从属于 **Pod** 之间的松耦合成为可能

> Service 用 **YAML（推荐）**或**JSON** 定义。

> **Service** 下的一组 **Pod** 通常由 _LabelSelector_ 来标记

> **Service** 通过一组 **Pod** 路由通信。

> **Service** 是一种抽象，它允许 **Pod** 死亡并在 K8S 中复制，而不会影响应用程序。在依赖的 **Pod（如应用程序中的前端和后端组件）** 之间进行发现和路由是由 **K8S Service** 处理的

> **Service** 匹配一组 **Pod** 是使用 `Label(标签)`和`Selector(选择器)`，它们是允许对 K8S 中的对象进行逻辑操作的一种分组原语，`Label(标签)`是附加在对象上的键值对

可以在 **ServiceSpec** 中通过 **_type_** 属性指定需要的 **Service** 类型

- ClusterIP： 在集群内部 IP 上暴露服务，此类型使 **Service** 只能从集群中访问
- NodePort： 通过每个 **Node** 上的 IP 和静态端口(NodePort)暴露服务。 **_NodePort_**服务会路由到 **_ClusterIP_** 服务，这个 **_ClusterIP_** 服务会自动创建。通过请求 **<NodeIP>:<NodePort>**，可以从集群的外部访问一个 **NodePort** 服务
- LoadBalancer：使用云提供商的负载均衡器（如果支持），可以向外部暴露服务。外部的负载均衡器可以路由到 **_NodePort_** 和 **_ClusterIP_**
- ExternalName：通过返回带有该名称的 **CNAME** 记录，使用任意名称(由 `spec` 的 **_externalName_**指定)公开 Service，不使用代理。这种类型需要 `kube-dns` V1.7 以上
